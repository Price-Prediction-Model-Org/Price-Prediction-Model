{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import *\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "import datetime\n",
    "# Query testing section for \n",
    "import requests\n",
    "from pprint import pprint\n",
    "\n",
    "from sqlalchemy import create_engine,inspect,extract, desc\n",
    "from sqlalchemy.ext.automap import automap_base\n",
    "from sqlalchemy.orm import Session\n",
    "\n",
    "from config import api_key,pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"Cryto_daily.csv\")\n",
    "print(\"Number of rows and columns:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = df[df['timestamp_year'] < 2021].iloc[:, 6:7].values\n",
    "test_set = df[df['timestamp_year'] >= 2021].iloc[:, 6:7].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "# from sklearn import joblib\n",
    "\n",
    "# import sklearn as sk\n",
    "# # And now to load...\n",
    "\n",
    "sc = MinMaxScaler(feature_range = (0, 1))\n",
    "sc.fit(training_set)\n",
    "\n",
    "# scaler_filename = \"scaler.save\"\n",
    "# sk.joblib.dump(sc, scaler_filename) \n",
    "import pickle\n",
    "# save the scaler\n",
    "pickle.dump(sc, open('scaler.pkl', 'wb'))\n",
    "\n",
    "\n",
    "training_set_scaled = sc.transform(training_set)\n",
    "\n",
    "# Creating a data structure with 60 time-steps and 1 output\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "for i in range(60, 2556):\n",
    "\n",
    "    X_train.append(training_set_scaled[i-60:i, 0])\n",
    "    y_train.append(training_set_scaled[i, 0])\n",
    "\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = pickle.load(open('scaler.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the predicted stock price of 2017\n",
    "dataset_train = df.iloc[:2556, 1:2]\n",
    "dataset_test = df.iloc[2556:, 1:2]\n",
    "\n",
    "dataset_total = pd.concat((dataset_train, dataset_test), axis = 0)\n",
    "dummy = dataset_total[len(dataset_total) - len(dataset_test) - 60:].values\n",
    "\n",
    "inputs = dummy.reshape(-1,1)\n",
    "inputs_transformed = sc.transform(inputs)\n",
    "\n",
    "X_test = []\n",
    "\n",
    "for i in range(60, 453):\n",
    "    X_test.append(inputs_transformed[i-60:i, 0])\n",
    "    \n",
    "X_test = np.array(X_test)\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>pos</th>\n",
       "      <th>vel</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>36</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>49</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>81</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   time  pos   vel  acc\n",
       "0     1    1   0.0  0.0\n",
       "1     2    4   3.0  0.0\n",
       "2     3    9   5.0  2.0\n",
       "3     4   16   7.0  2.0\n",
       "4     5   25   9.0  2.0\n",
       "5     6   36  11.0  2.0\n",
       "6     7   49  13.0  2.0\n",
       "7     8   64  15.0  2.0\n",
       "8     9   81  17.0  2.0\n",
       "9    10  100  19.0  2.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = pd.DataFrame(\n",
    "    {'time': [1,2,3,4,5,6,7,8,9,10]}\n",
    ")\n",
    "\n",
    "temp['pos'] = temp['time'] ** 2\n",
    "\n",
    "temp['vel'] = temp['pos'].diff()\n",
    "temp['acc'] = temp['vel'].diff()\n",
    "temp = temp.fillna(0).copy()\n",
    "temp\n",
    "\n",
    "\n",
    "\n",
    "# temp['ma_3_day'] = temp['values'].rolling(3, min_periods = 1).mean()\n",
    "# temp['ma_5_day'] = temp['values'].rolling(5, min_periods = 1).mean()\n",
    "# temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = joblib.load(scaler_filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loaded = tf.keras.models.load_model('Model_Testing/Crypto_Models/Trained_model_2_daily_BTC_4L_50N_0p1D_trainUpTo2021.h5', compile = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_stock_price = model_loaded.predict(X_test)\n",
    "predicted_stock_price = sc.inverse_transform(predicted_stock_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('postgres://tewbhkurvrgekc:1f0da88da60573b11de3b91d39821c8127b145e05e2766d00a187f83ddab3d15@ec2-3-228-75-39.compute-1.amazonaws.com:5432/d4p4835fs7o47m')\n",
    "session = Session(engine)\n",
    "\n",
    "Base=automap_base()\n",
    "Base.prepare(engine, reflect=True)\n",
    "print(Base.classes.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_crypto_data(results):\n",
    "    \"\"\"function to convert sql queries for a crypto currency into a usable dataframe\n",
    "\n",
    "    Args:\n",
    "        coin ([string]): [which crypto to get]\n",
    "        table ([type]): [SQL table name]\n",
    "        \n",
    "    Returns:\n",
    "        [type]: [description]\n",
    "    \"\"\"\n",
    "    # sql query with specified coin, gets all data, in order hopefully\n",
    "    \n",
    "    # converts results to a dataframe\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS FUNCTION IS MODIFIED IN THE FLASK APP\n",
    "\n",
    "def predict_past_year(session, coin, model, scaler):\n",
    "    \"\"\"Function to make predictions for the past year in one day increments\n",
    "\n",
    "    Args:\n",
    "        session (object): connection to sql db\n",
    "        coin (string): [coin that is going to be predicted]\n",
    "        model ([loaded LSTM model]): [trained  model loaded in from directory]\n",
    "\n",
    "    Returns:\n",
    "        past_year_dict [dict]: [dictionary containing dates, predictions, real prices]\n",
    "    \"\"\"\n",
    "    \n",
    "    look_back = 60\n",
    "    one_year_ago = datetime.date.today() - datetime.timedelta(days=(365 + look_back))\n",
    "    \n",
    "    results = session.query(cp.timestamp_date, cp.close).filter(cp.coin == coin).filter(cp.timestamp_date >= one_year_ago).order_by(cp.timestamp_date).all()\n",
    "    \n",
    "    dates = [str(x[0]) for x in results]\n",
    "    close_prices = [float(x[1]) for x in results]\n",
    "\n",
    "    inputs = np.array(close_prices).reshape(-1,1)\n",
    "\n",
    "    inputs_transformed = scaler.transform(inputs)\n",
    "\n",
    "    X_test = []\n",
    "    look_back = 60\n",
    "\n",
    "    for i in range(look_back, len(inputs_transformed)):\n",
    "        \n",
    "        X_test.append(inputs_transformed[i-60:i, 0])\n",
    "\n",
    "    X_test = np.array(X_test)\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "    \n",
    "    \n",
    "    predicted_stock_price = model.predict(X_test)\n",
    "    predicted_stock_price = scaler.inverse_transform(predicted_stock_price)\n",
    "    \n",
    "    \n",
    "    past_year_dict = {\n",
    "        'dates': dates[60:],\n",
    "        'real_prices': close_prices[60:],\n",
    "        'predictions': [float(x) for x in list(predicted_stock_price[:,0])]\n",
    "    }\n",
    "    \n",
    "    session.close()\n",
    "    \n",
    "    return past_year_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_dates(most_recent_date, predict_days):\n",
    "    \n",
    "    prediction_dates = pd.date_range(most_recent_date, periods=predict_days+1).tolist()[1:]\n",
    "    \n",
    "    return prediction_dates\n",
    "\n",
    "\n",
    "# THIS FUNCTION IS MODIFIED IN THE FLASK APP\n",
    "\n",
    "def predict_X_days(session, coin, model, predict_days, scaler):\n",
    "    \"\"\"Predict 'days' into the future by feeding back daily predictions into model\n",
    "\n",
    "    Args:\n",
    "        session (object): connection to sql db\n",
    "        coin (string): [coin that is going to be predicted]\n",
    "        model ([loaded LSTM model]): [trained  model loaded in from directory]\n",
    "        predict_days ([int]): [Number of days to predict into the future]\n",
    "\n",
    "    Returns:\n",
    "        x_days_dict [dict]: [dictionary containing dates, predictions, real prices]\n",
    "    \"\"\"\n",
    "    \n",
    "    look_back = 60\n",
    "    ninety_days_back = datetime.date.today() - datetime.timedelta(days=90)\n",
    "    \n",
    "    results = session.query(cp.timestamp_date, cp.close).filter(cp.coin == coin).filter(cp.timestamp_date >= ninety_days_back).order_by(cp.timestamp_date).all()\n",
    "    \n",
    "    dates = [x[0] for x in results]\n",
    "    close_prices = [float(x[1]) for x in results]\n",
    "    \n",
    "    inputs_list = close_prices[-60:]\n",
    "    inputs = np.array(inputs_list).reshape(-1,1)\n",
    "    \n",
    "    sliding_inputs = scaler.transform(inputs)\n",
    "    \n",
    "    predictions = []\n",
    "\n",
    "    for _ in range(predict_days):\n",
    "        \n",
    "        prediction = model.predict(sliding_inputs.reshape(1,-1,1))\n",
    "        predictions.append(prediction[:,0][0])\n",
    "        \n",
    "        sliding_inputs = sliding_inputs.ravel().tolist()\n",
    "        del sliding_inputs[0]\n",
    "        sliding_inputs.append(prediction[:,0][0])\n",
    "        \n",
    "        sliding_inputs = np.array(sliding_inputs).reshape(1,-1,1)\n",
    "        \n",
    "    predictions = np.array(predictions).reshape(-1,1)\n",
    "    predicted_stock_price = scaler.inverse_transform(predictions)\n",
    "    \n",
    "    pred_dates = predict_dates(dates[-1], predict_days)\n",
    "        \n",
    "    forecast_dict = {\n",
    "        'sliding_inputs': sliding_inputs,\n",
    "        'real_price_dates': dates,\n",
    "        'pred_dates': pred_dates,\n",
    "        'real_prices': close_prices,\n",
    "        'predictions': list(predicted_stock_price[:,0])\n",
    "    }\n",
    "        \n",
    "    session.close()\n",
    "    \n",
    "    return forecast_dict\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "*****************************************************\n",
    "ACCELERATION FUNCTION!!\n",
    "*****************************************************\n",
    "'''\n",
    "\n",
    "def predict_dates(most_recent_date, predict_days):\n",
    "    \n",
    "    prediction_dates = pd.date_range(most_recent_date, periods=predict_days+1).tolist()[1:]\n",
    "    \n",
    "    return prediction_dates\n",
    "\n",
    "\n",
    "# THIS FUNCTION IS MODIFIED IN THE FLASK APP\n",
    "\n",
    "def predict_X_days(session, coin, model, predict_days, scaler):\n",
    "    \"\"\"Predict 'days' into the future by feeding back daily predictions into model\n",
    "\n",
    "    Args:\n",
    "        session (object): connection to sql db\n",
    "        coin (string): [coin that is going to be predicted]\n",
    "        model ([loaded LSTM model]): [trained  model loaded in from directory]\n",
    "        predict_days ([int]): [Number of days to predict into the future]\n",
    "\n",
    "    Returns:\n",
    "        x_days_dict [dict]: [dictionary containing dates, predictions, real prices]\n",
    "    \"\"\"\n",
    "    \n",
    "    look_back = 60\n",
    "    ninety_days_back = datetime.date.today() - datetime.timedelta(days=90)\n",
    "    \n",
    "    results = session.query(cp.timestamp_date, cp.close).filter(cp.coin == coin).filter(cp.timestamp_date >= ninety_days_back).order_by(cp.timestamp_date).all()\n",
    "    \n",
    "    dates = [x[0] for x in results]\n",
    "    close_prices = [float(x[1]) for x in results]\n",
    "    \n",
    "    features_dict = {\n",
    "        'close': close_prices\n",
    "    }\n",
    "    \n",
    "    features_df = pd.DataFrame(features_dict)\n",
    "    # create 20 and 50 day moving average columns\n",
    "    features_df['ma_20_day'] = features_df['close'].rolling(20, min_periods=1).mean()\n",
    "    features_df['ma_50_day'] = features_df['close'].rolling(50, min_periods=1).mean()\n",
    "\n",
    "    # create close price velocity and accelaration columns\n",
    "    features_df['close_velo'] = features_df['close'].diff()\n",
    "    features_df['close_acc'] = features_df['close_velo'].diff()\n",
    "    features_df = features_df.fillna(0)\n",
    "    \n",
    "\n",
    "    \n",
    "    inputs_list = features\n",
    "    inputs = np.array(inputs_list).reshape(-1,5)\n",
    "    \n",
    "    sliding_inputs = scaler.transform(inputs)\n",
    "    \n",
    "    predictions = []\n",
    "\n",
    "    for _ in range(predict_days):\n",
    "        \n",
    "        prediction = model.predict(sliding_inputs.reshape(1,-1,1))\n",
    "        predictions.append(prediction[:,0][0])\n",
    "        \n",
    "        sliding_inputs = sliding_inputs.ravel().tolist()\n",
    "        del sliding_inputs[0]\n",
    "        sliding_inputs.append(prediction[:,0][0])\n",
    "        \n",
    "        sliding_inputs = np.array(sliding_inputs).reshape(1,-1,1)\n",
    "        \n",
    "    predictions = np.array(predictions).reshape(-1,1)\n",
    "    predicted_stock_price = scaler.inverse_transform(predictions)\n",
    "    \n",
    "    pred_dates = predict_dates(dates[-1], predict_days)\n",
    "        \n",
    "    forecast_dict = {\n",
    "        'sliding_inputs': sliding_inputs,\n",
    "        'real_price_dates': dates,\n",
    "        'pred_dates': pred_dates,\n",
    "        'real_prices': close_prices,\n",
    "        'predictions': list(predicted_stock_price[:,0])\n",
    "    }\n",
    "        \n",
    "    session.close()\n",
    "    \n",
    "    return forecast_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('postgres://tewbhkurvrgekc:1f0da88da60573b11de3b91d39821c8127b145e05e2766d00a187f83ddab3d15@ec2-3-228-75-39.compute-1.amazonaws.com:5432/d4p4835fs7o47m')\n",
    "session = Session(engine)\n",
    "\n",
    "Base=automap_base()\n",
    "Base.prepare(engine, reflect=True)\n",
    "print(Base.classes.keys())\n",
    "\n",
    "\n",
    "model_loaded = tf.keras.models.load_model('Model_Testing/Crypto_Models/Trained_model_4_daily_BTC_4L_50N_0p1D_50epo_trainUpTo2021.h5', compile = False)\n",
    "\n",
    "scaler = pickle.load(open('scaler.pkl', 'rb'))\n",
    "\n",
    "forecast_Xdays_dict = predict_X_days(session, 'BTC', model_loaded, 60, scaler)\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(20,10))\n",
    "\n",
    "\n",
    "real_price_dates_strings = [str(x) for x in forecast_Xdays_dict['real_price_dates']]\n",
    "pred_dates_strings = [str(x) for x in forecast_Xdays_dict['pred_dates']]\n",
    "# Visualising the results\n",
    "\n",
    "# ax.xaxis.set_major_formatter(mdates)\n",
    "ax.plot(real_price_dates_strings,forecast_Xdays_dict['real_prices'], color = 'red', label = 'Real BTC Price')\n",
    "ax.plot(pred_dates_strings,forecast_Xdays_dict['predictions'], color = 'blue', label = 'Predicted BTC Price')\n",
    "\n",
    "ax.set_xticks(np.arange(0,(len(real_price_dates_strings)+(len(pred_dates_strings))),10))\n",
    "ax.set_title('BTC Price Prediction')\n",
    "ax.set_xlabel('Time')\n",
    "ax.set_ylabel('BTC Price (USD)')\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "engine = create_engine(f'postgresql://postgres:1120@localhost:5432/Crypto_db')\n",
    "session = Session(engine)\n",
    "\n",
    "Base=automap_base()\n",
    "Base.prepare(engine, reflect=True)\n",
    "print(Base.classes.keys())\n",
    "\n",
    "\n",
    "cp = Base.classes.crypto_price\n",
    "\n",
    "\n",
    "model_loaded = tf.keras.models.load_model('Model_Testing/Crypto_Models/TM_5_daily_BTC_3L_100N_100N_50N_RS_TTF_0p1D_20epo_trainUpTo2021.h5', compile = False)\n",
    "\n",
    "scaler = pickle.load(open('scaler.pkl', 'rb'))\n",
    "\n",
    "past_year_dict = predict_past_year(session, 'BTC', model_loaded, scaler)\n",
    "\n",
    "session.close()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(20,10))\n",
    "\n",
    "\n",
    "dates_strings = [str(x) for x in past_year_dict['dates']]\n",
    "# Visualising the results\n",
    "\n",
    "# ax.xaxis.set_major_formatter(mdates)\n",
    "ax.plot(dates_strings,past_year_dict['real_prices'], color = 'red', label = 'Real BTC Price')\n",
    "ax.plot(dates_strings,past_year_dict['predictions'], color = 'blue', label = 'Predicted BTC Price')\n",
    "\n",
    "ax.set_xticks(np.arange(0,366,50))\n",
    "ax.set_title('BTC Price Prediction')\n",
    "ax.set_xlabel('Time')\n",
    "ax.set_ylabel('BTC Price (USD)')\n",
    "\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6ffeae461081b98ae86352a0851f1155f0b2a8eafa30374dc3cd8f018d3c1071"
  },
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit ('PythonData': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
